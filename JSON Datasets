from pyspark.sql import SparkSession from pyspark.sql.functions import col

if __name__ == "__main__":
    spark = SparkSession.builder.master("local[*]").appName("JSON Data").getOrCreate()
    spark.sparkContext.setLogLevel('ERROR')
    df = spark.read.json('internet-users-per-100.json')
    df.printSchema()
    json_str = ['{"n2015":"0.5", "n_":"Tomania"}','{"n2015":"100.0", "n_":"Osterlich"}']
    usersRDD = spark.sparkContext.parallelize(json_str)
    moreUsers= spark.read.json(usersRDD)
    moreUsers.show()
    dfAll = df.union(moreUsers)
    dfAll.filter(col("n2015") > 95).show()
    dfAll.filter(col("n2015") < 2).show()
    spark.stop()
